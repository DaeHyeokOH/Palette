{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":163658,"status":"ok","timestamp":1694949035452,"user":{"displayName":"DaeHyeok OH","userId":"18061477472662081697"},"user_tz":-540},"id":"ojnGvoh-MqGw"},"outputs":[],"source":["from torchvision.transforms import transforms\n","from torch.utils.data import Dataset\n","import pickle\n","import os\n","import torch\n","import numpy as np\n","\n","#set device\n","device = torch.device(\"mps\" if torch.cuda.is_available() else \"cpu\")\n","#constants\n","VIDEO = 40\n","PARTICIPANT = 32\n","CHANNEL = 32\n","SESSION = 63\n","\n","\n","#Make Datasets\n","class Arousal_Dataset(Dataset):\n","    def __init__(self, data_path, train = None):\n","        super().__init__\n","        self.data_path = data_path\n","        self.palette_name_list = os.listdir(data_path)\n","\n","    def __getitem__(self, index):\n","        palette_path = os.path.join(self.data_path, self.palette_name_list[index])\n","        palette = pickle.load(open(palette_path, 'rb'))\n","        palette = np.float32(palette)\n","        to_tensor = transforms.ToTensor()\n","        transformed_palette = to_tensor(palette)\n","        x_data = transformed_palette\n","\n","        palette_split_list = self.palette_name_list[index].split('_')\n","        Truth_label = palette_split_list[6]\n","\n","        if Truth_label[0 :2] == 'HA':\n","            y_data = 1\n","        else:\n","            y_data = 0\n","\n","        return x_data, y_data\n","\n","    def __len__(self):\n","        return len(self.palette_name_list)\n","\n","# #데이터 전처리\n","# transform = transforms.Compose(\n","#     [transforms.ToTensor(),transforms.Normalize((0.5 , 0.5, 0.5), (0.5, 0.5, 0.5))]\n","# )\n","\n","\n","#총 데이터 num :32 * 40 * 63, batch_size는 이의 약수\n","batch_size = 32\n","Data_Path_Train = \"./Data/data_palettes_train/\"\n","Data_Path_Test = \"./Data/data_palettes_test/\"\n","\n","#test_데이터, train_데이터 불러오고 저장\n","train_set = Arousal_Dataset(data_path = Data_Path_Train, train = True)\n","\n","train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers = 0)\n","\n","test_set = Arousal_Dataset(data_path = Data_Path_Test, train = False)\n","\n","test_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size, shuffle = False, num_workers = 0)\n","\n","#output clasees\n","classes =  (0, 1)\n"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":446,"status":"ok","timestamp":1694949074035,"user":{"displayName":"DaeHyeok OH","userId":"18061477472662081697"},"user_tz":-540},"id":"AKK44tOYMqGx"},"outputs":[],"source":["import torch.nn as nn\n","import torch.nn.functional as F\n","\n","class SmallCNN(nn.Module):\n","    def __init__(self):\n","        super(SmallCNN, self).__init__()\n","\n","        # Convolutional layers\n","        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)\n","        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n","        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n","\n","        # Batch normalization layers\n","        self.batch_norm1 = nn.BatchNorm2d(16)\n","        self.batch_norm2 = nn.BatchNorm2d(32)\n","        self.batch_norm3 = nn.BatchNorm2d(64)\n","\n","        # Max pooling layer\n","        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n","\n","        # Fully connected layers\n","        self.fc1 = nn.Linear(64, 32)\n","        self.fc2 = nn.Linear(32, 2)  # 2 output classes (0 and 1)\n","\n","        # Dropout layer to prevent overfitting\n","        self.dropout = nn.Dropout(0.5)\n","\n","    def forward(self, x):\n","        print(f\"initial x {x.shape}\")\n","        x.to(device)\n","        x = self.pool(self.batch_norm1(torch.relu(self.conv1(x))))\n","        x.to(device)\n","        print(f\"conv1 x {x.shape}\")\n","        x = self.pool(self.batch_norm2(torch.relu(self.conv2(x))))\n","        x.to(device)\n","        print(f\"conv2 x {x.shape}\")\n","        x = self.pool(self.batch_norm3(torch.relu(self.conv3(x))))\n","        x.to(device)\n","        print(f\"conv3 x {x.shape}\")\n","\n","        # print(type(x))\n","        # print(x.shape)\n","        #should keep its own batch size\n","        x = x.view(32, -1)  # Flatten the tensor\n","        x.to(device)\n","        print(f\"After flatten x {x.shape}\")\n","        x = torch.relu(self.fc1(x))\n","        x.to(device)\n","        print(f\"After linear x {x.shape}\")\n","        x = self.dropout(x)  # Apply dropout to prevent overfitting\n","        x.to(device)\n","        print(f\"After dropout x {x.shape}\")\n","        x = self.fc2(x)\n","        print(f\"output x{x.shape}\")\n","\n","        return x\n","\n","net = SmallCNN()\n","\n","\n","#\"net\" model runs through GPU\n","net.to(device)\n","\n","#Set Optimizer and loss function\n","import torch.optim as optim\n","\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.SGD(net.parameters(), lr=0.015, momentum = 0.8)"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["6c1a9e6e948346e08db35c1cdaa98142","57db90486c05493696ccd5dd12e1fa76","83f6d083d59f4370adbf5ed05163fe80","f3fc3fa138614c63849cc9788bcdfb63","5ae44592655b441b8a25dae83e08f514","4106fcd31a1b4ab8b7ea3a73d4feef59","8d439083db004ee2ad1e390d5498967c","1a37b57b03c141afb23bd96c9c60f2c8","44f30e031c6a4eb4ba80c4c47c11fcb2","6402a280118a477eb43772732850421e","cbbe9289e69b4786820ddb7f88d860ce"]},"id":"wK6lrJiHMqGx","outputId":"7c020a1b-5177-48b6-efbf-e6ca688f720f"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6f7195d5e77d4af9ad9bb44324941694","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1890 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["start learning!!!\n","initial x torch.Size([32, 3, 9, 9])\n","conv1 x torch.Size([32, 16, 4, 4])\n","conv2 x torch.Size([32, 32, 2, 2])\n","conv3 x torch.Size([32, 64, 1, 1])\n","After flatten x torch.Size([32, 64])\n","After linear x torch.Size([32, 32])\n","After dropout x torch.Size([32, 32])\n","output xtorch.Size([32, 2])\n","initial x torch.Size([32, 3, 9, 9])\n","conv1 x torch.Size([32, 16, 4, 4])\n","conv2 x torch.Size([32, 32, 2, 2])\n","conv3 x torch.Size([32, 64, 1, 1])\n","After flatten x torch.Size([32, 64])\n","After linear x torch.Size([32, 32])\n","After dropout x torch.Size([32, 32])\n","output xtorch.Size([32, 2])\n","initial x torch.Size([32, 3, 9, 9])\n","conv1 x torch.Size([32, 16, 4, 4])\n","conv2 x torch.Size([32, 32, 2, 2])\n","conv3 x torch.Size([32, 64, 1, 1])\n","After flatten x torch.Size([32, 64])\n","After linear x torch.Size([32, 32])\n","After dropout x torch.Size([32, 32])\n","output xtorch.Size([32, 2])\n","initial x torch.Size([32, 3, 9, 9])\n","conv1 x torch.Size([32, 16, 4, 4])\n","conv2 x torch.Size([32, 32, 2, 2])\n","conv3 x torch.Size([32, 64, 1, 1])\n","After flatten x torch.Size([32, 64])\n","After linear x torch.Size([32, 32])\n","After dropout x torch.Size([32, 32])\n","output xtorch.Size([32, 2])\n","initial x torch.Size([32, 3, 9, 9])\n","conv1 x torch.Size([32, 16, 4, 4])\n","conv2 x torch.Size([32, 32, 2, 2])\n","conv3 x torch.Size([32, 64, 1, 1])\n","After flatten x torch.Size([32, 64])\n","After linear x torch.Size([32, 32])\n","After dropout x torch.Size([32, 32])\n","output xtorch.Size([32, 2])\n","initial x torch.Size([32, 3, 9, 9])\n","conv1 x torch.Size([32, 16, 4, 4])\n","conv2 x torch.Size([32, 32, 2, 2])\n","conv3 x torch.Size([32, 64, 1, 1])\n","After flatten x torch.Size([32, 64])\n","After linear x torch.Size([32, 32])\n","After dropout x torch.Size([32, 32])\n","output xtorch.Size([32, 2])\n","initial x torch.Size([32, 3, 9, 9])\n","conv1 x torch.Size([32, 16, 4, 4])\n","conv2 x torch.Size([32, 32, 2, 2])\n","conv3 x torch.Size([32, 64, 1, 1])\n","After flatten x torch.Size([32, 64])\n","After linear x torch.Size([32, 32])\n","After dropout x torch.Size([32, 32])\n","output xtorch.Size([32, 2])\n","initial x torch.Size([32, 3, 9, 9])\n","conv1 x torch.Size([32, 16, 4, 4])\n","conv2 x torch.Size([32, 32, 2, 2])\n","conv3 x torch.Size([32, 64, 1, 1])\n","After flatten x torch.Size([32, 64])\n","After linear x torch.Size([32, 32])\n","After dropout x torch.Size([32, 32])\n","output xtorch.Size([32, 2])\n","initial x torch.Size([32, 3, 9, 9])\n","conv1 x torch.Size([32, 16, 4, 4])\n","conv2 x torch.Size([32, 32, 2, 2])\n","conv3 x torch.Size([32, 64, 1, 1])\n","After flatten x torch.Size([32, 64])\n","After linear x torch.Size([32, 32])\n","After dropout x torch.Size([32, 32])\n","output xtorch.Size([32, 2])\n","initial x torch.Size([32, 3, 9, 9])\n","conv1 x torch.Size([32, 16, 4, 4])\n","conv2 x torch.Size([32, 32, 2, 2])\n","conv3 x torch.Size([32, 64, 1, 1])\n","After flatten x torch.Size([32, 64])\n","After linear x torch.Size([32, 32])\n","After dropout x torch.Size([32, 32])\n","output xtorch.Size([32, 2])\n","initial x torch.Size([32, 3, 9, 9])\n","conv1 x torch.Size([32, 16, 4, 4])\n","conv2 x torch.Size([32, 32, 2, 2])\n","conv3 x torch.Size([32, 64, 1, 1])\n","After flatten x torch.Size([32, 64])\n","After linear x torch.Size([32, 32])\n","After dropout x torch.Size([32, 32])\n","output xtorch.Size([32, 2])\n","initial x torch.Size([32, 3, 9, 9])\n","conv1 x torch.Size([32, 16, 4, 4])\n","conv2 x torch.Size([32, 32, 2, 2])\n","conv3 x torch.Size([32, 64, 1, 1])\n","After flatten x torch.Size([32, 64])\n","After linear x torch.Size([32, 32])\n","After dropout x torch.Size([32, 32])\n","output xtorch.Size([32, 2])\n","initial x torch.Size([32, 3, 9, 9])\n","conv1 x torch.Size([32, 16, 4, 4])\n","conv2 x torch.Size([32, 32, 2, 2])\n","conv3 x torch.Size([32, 64, 1, 1])\n","After flatten x torch.Size([32, 64])\n","After linear x torch.Size([32, 32])\n","After dropout x torch.Size([32, 32])\n","output xtorch.Size([32, 2])\n","initial x torch.Size([32, 3, 9, 9])\n","conv1 x torch.Size([32, 16, 4, 4])\n","conv2 x torch.Size([32, 32, 2, 2])\n","conv3 x torch.Size([32, 64, 1, 1])\n","After flatten x torch.Size([32, 64])\n","After linear x torch.Size([32, 32])\n","After dropout x torch.Size([32, 32])\n","output xtorch.Size([32, 2])\n","initial x torch.Size([32, 3, 9, 9])\n","conv1 x torch.Size([32, 16, 4, 4])\n","conv2 x torch.Size([32, 32, 2, 2])\n","conv3 x torch.Size([32, 64, 1, 1])\n","After flatten x torch.Size([32, 64])\n","After linear x torch.Size([32, 32])\n","After dropout x torch.Size([32, 32])\n","output xtorch.Size([32, 2])\n","initial x torch.Size([32, 3, 9, 9])\n","conv1 x torch.Size([32, 16, 4, 4])\n","conv2 x torch.Size([32, 32, 2, 2])\n","conv3 x torch.Size([32, 64, 1, 1])\n","After flatten x torch.Size([32, 64])\n","After linear x torch.Size([32, 32])\n","After dropout x torch.Size([32, 32])\n","output xtorch.Size([32, 2])\n","initial x torch.Size([32, 3, 9, 9])\n","conv1 x torch.Size([32, 16, 4, 4])\n","conv2 x torch.Size([32, 32, 2, 2])\n","conv3 x torch.Size([32, 64, 1, 1])\n","After flatten x torch.Size([32, 64])\n","After linear x torch.Size([32, 32])\n","After dropout x torch.Size([32, 32])\n","output xtorch.Size([32, 2])\n","initial x torch.Size([32, 3, 9, 9])\n","conv1 x torch.Size([32, 16, 4, 4])\n","conv2 x torch.Size([32, 32, 2, 2])\n","conv3 x torch.Size([32, 64, 1, 1])\n","After flatten x torch.Size([32, 64])\n","After linear x torch.Size([32, 32])\n","After dropout x torch.Size([32, 32])\n","output xtorch.Size([32, 2])\n","initial x torch.Size([32, 3, 9, 9])\n","conv1 x torch.Size([32, 16, 4, 4])\n","conv2 x torch.Size([32, 32, 2, 2])\n","conv3 x torch.Size([32, 64, 1, 1])\n","After flatten x torch.Size([32, 64])\n","After linear x torch.Size([32, 32])\n","After dropout x torch.Size([32, 32])\n","output xtorch.Size([32, 2])\n","initial x torch.Size([32, 3, 9, 9])\n","conv1 x torch.Size([32, 16, 4, 4])\n","conv2 x torch.Size([32, 32, 2, 2])\n","conv3 x torch.Size([32, 64, 1, 1])\n","After flatten x torch.Size([32, 64])\n","After linear x torch.Size([32, 32])\n","After dropout x torch.Size([32, 32])\n","output xtorch.Size([32, 2])\n","initial x torch.Size([32, 3, 9, 9])\n","conv1 x torch.Size([32, 16, 4, 4])\n","conv2 x torch.Size([32, 32, 2, 2])\n","conv3 x torch.Size([32, 64, 1, 1])\n","After flatten x torch.Size([32, 64])\n","After linear x torch.Size([32, 32])\n","After dropout x torch.Size([32, 32])\n","output xtorch.Size([32, 2])\n","initial x torch.Size([32, 3, 9, 9])\n","conv1 x torch.Size([32, 16, 4, 4])\n","conv2 x torch.Size([32, 32, 2, 2])\n","conv3 x torch.Size([32, 64, 1, 1])\n","After flatten x torch.Size([32, 64])\n","After linear x torch.Size([32, 32])\n","After dropout x torch.Size([32, 32])\n","output xtorch.Size([32, 2])\n","initial x torch.Size([32, 3, 9, 9])\n","conv1 x torch.Size([32, 16, 4, 4])\n","conv2 x torch.Size([32, 32, 2, 2])\n","conv3 x torch.Size([32, 64, 1, 1])\n","After flatten x torch.Size([32, 64])\n","After linear x torch.Size([32, 32])\n","After dropout x torch.Size([32, 32])\n","output xtorch.Size([32, 2])\n","initial x torch.Size([32, 3, 9, 9])\n","conv1 x torch.Size([32, 16, 4, 4])\n","conv2 x torch.Size([32, 32, 2, 2])\n","conv3 x torch.Size([32, 64, 1, 1])\n","After flatten x torch.Size([32, 64])\n","After linear x torch.Size([32, 32])\n","After dropout x torch.Size([32, 32])\n","output xtorch.Size([32, 2])\n","initial x torch.Size([32, 3, 9, 9])\n","conv1 x torch.Size([32, 16, 4, 4])\n","conv2 x torch.Size([32, 32, 2, 2])\n","conv3 x torch.Size([32, 64, 1, 1])\n","After flatten x torch.Size([32, 64])\n","After linear x torch.Size([32, 32])\n","After dropout x torch.Size([32, 32])\n","output xtorch.Size([32, 2])\n","initial x torch.Size([32, 3, 9, 9])\n","conv1 x torch.Size([32, 16, 4, 4])\n","conv2 x torch.Size([32, 32, 2, 2])\n","conv3 x torch.Size([32, 64, 1, 1])\n","After flatten x torch.Size([32, 64])\n","After linear x torch.Size([32, 32])\n","After dropout x torch.Size([32, 32])\n","output xtorch.Size([32, 2])\n","initial x torch.Size([32, 3, 9, 9])\n","conv1 x torch.Size([32, 16, 4, 4])\n","conv2 x torch.Size([32, 32, 2, 2])\n","conv3 x torch.Size([32, 64, 1, 1])\n","After flatten x torch.Size([32, 64])\n","After linear x torch.Size([32, 32])\n","After dropout x torch.Size([32, 32])\n","output xtorch.Size([32, 2])\n","initial x torch.Size([32, 3, 9, 9])\n","conv1 x torch.Size([32, 16, 4, 4])\n","conv2 x torch.Size([32, 32, 2, 2])\n","conv3 x torch.Size([32, 64, 1, 1])\n","After flatten x torch.Size([32, 64])\n","After linear x torch.Size([32, 32])\n","After dropout x torch.Size([32, 32])\n","output xtorch.Size([32, 2])\n","initial x torch.Size([32, 3, 9, 9])\n","conv1 x torch.Size([32, 16, 4, 4])\n","conv2 x torch.Size([32, 32, 2, 2])\n","conv3 x torch.Size([32, 64, 1, 1])\n","After flatten x torch.Size([32, 64])\n","After linear x torch.Size([32, 32])\n","After dropout x torch.Size([32, 32])\n","output xtorch.Size([32, 2])\n","initial x torch.Size([32, 3, 9, 9])\n","conv1 x torch.Size([32, 16, 4, 4])\n","conv2 x torch.Size([32, 32, 2, 2])\n","conv3 x torch.Size([32, 64, 1, 1])\n","After flatten x torch.Size([32, 64])\n","After linear x torch.Size([32, 32])\n","After dropout x torch.Size([32, 32])\n","output xtorch.Size([32, 2])\n","initial x torch.Size([32, 3, 9, 9])\n","conv1 x torch.Size([32, 16, 4, 4])\n","conv2 x torch.Size([32, 32, 2, 2])\n","conv3 x torch.Size([32, 64, 1, 1])\n","After flatten x torch.Size([32, 64])\n","After linear x torch.Size([32, 32])\n","After dropout x torch.Size([32, 32])\n","output xtorch.Size([32, 2])\n","initial x torch.Size([32, 3, 9, 9])\n","conv1 x torch.Size([32, 16, 4, 4])\n","conv2 x torch.Size([32, 32, 2, 2])\n","conv3 x torch.Size([32, 64, 1, 1])\n","After flatten x torch.Size([32, 64])\n","After linear x torch.Size([32, 32])\n","After dropout x torch.Size([32, 32])\n","output xtorch.Size([32, 2])\n","initial x torch.Size([32, 3, 9, 9])\n","conv1 x torch.Size([32, 16, 4, 4])\n","conv2 x torch.Size([32, 32, 2, 2])\n","conv3 x torch.Size([32, 64, 1, 1])\n","After flatten x torch.Size([32, 64])\n","After linear x torch.Size([32, 32])\n","After dropout x torch.Size([32, 32])\n","output xtorch.Size([32, 2])\n","initial x torch.Size([32, 3, 9, 9])\n","conv1 x torch.Size([32, 16, 4, 4])\n","conv2 x torch.Size([32, 32, 2, 2])\n","conv3 x torch.Size([32, 64, 1, 1])\n","After flatten x torch.Size([32, 64])\n","After linear x torch.Size([32, 32])\n","After dropout x torch.Size([32, 32])\n","output xtorch.Size([32, 2])\n","initial x torch.Size([32, 3, 9, 9])\n","conv1 x torch.Size([32, 16, 4, 4])\n","conv2 x torch.Size([32, 32, 2, 2])\n","conv3 x torch.Size([32, 64, 1, 1])\n","After flatten x torch.Size([32, 64])\n","After linear x torch.Size([32, 32])\n","After dropout x torch.Size([32, 32])\n","output xtorch.Size([32, 2])\n","initial x torch.Size([32, 3, 9, 9])\n","conv1 x torch.Size([32, 16, 4, 4])\n","conv2 x torch.Size([32, 32, 2, 2])\n","conv3 x torch.Size([32, 64, 1, 1])\n","After flatten x torch.Size([32, 64])\n","After linear x torch.Size([32, 32])\n","After dropout x torch.Size([32, 32])\n","output xtorch.Size([32, 2])\n","initial x torch.Size([32, 3, 9, 9])\n","conv1 x torch.Size([32, 16, 4, 4])\n","conv2 x torch.Size([32, 32, 2, 2])\n","conv3 x torch.Size([32, 64, 1, 1])\n","After flatten x torch.Size([32, 64])\n","After linear x torch.Size([32, 32])\n","After dropout x torch.Size([32, 32])\n","output xtorch.Size([32, 2])\n","initial x torch.Size([32, 3, 9, 9])\n","conv1 x torch.Size([32, 16, 4, 4])\n","conv2 x torch.Size([32, 32, 2, 2])\n","conv3 x torch.Size([32, 64, 1, 1])\n","After flatten x torch.Size([32, 64])\n","After linear x torch.Size([32, 32])\n","After dropout x torch.Size([32, 32])\n","output xtorch.Size([32, 2])\n","initial x torch.Size([32, 3, 9, 9])\n","conv1 x torch.Size([32, 16, 4, 4])\n","conv2 x torch.Size([32, 32, 2, 2])\n","conv3 x torch.Size([32, 64, 1, 1])\n","After flatten x torch.Size([32, 64])\n","After linear x torch.Size([32, 32])\n","After dropout x torch.Size([32, 32])\n","output xtorch.Size([32, 2])\n","initial x torch.Size([32, 3, 9, 9])\n","conv1 x torch.Size([32, 16, 4, 4])\n","conv2 x torch.Size([32, 32, 2, 2])\n","conv3 x torch.Size([32, 64, 1, 1])\n","After flatten x torch.Size([32, 64])\n","After linear x torch.Size([32, 32])\n","After dropout x torch.Size([32, 32])\n","output xtorch.Size([32, 2])\n","initial x torch.Size([32, 3, 9, 9])\n","conv1 x torch.Size([32, 16, 4, 4])\n","conv2 x torch.Size([32, 32, 2, 2])\n","conv3 x torch.Size([32, 64, 1, 1])\n","After flatten x torch.Size([32, 64])\n","After linear x torch.Size([32, 32])\n","After dropout x torch.Size([32, 32])\n","output xtorch.Size([32, 2])\n","initial x torch.Size([32, 3, 9, 9])\n","conv1 x torch.Size([32, 16, 4, 4])\n","conv2 x torch.Size([32, 32, 2, 2])\n","conv3 x torch.Size([32, 64, 1, 1])\n","After flatten x torch.Size([32, 64])\n","After linear x torch.Size([32, 32])\n","After dropout x torch.Size([32, 32])\n","output xtorch.Size([32, 2])\n","initial x torch.Size([32, 3, 9, 9])\n","conv1 x torch.Size([32, 16, 4, 4])\n","conv2 x torch.Size([32, 32, 2, 2])\n","conv3 x torch.Size([32, 64, 1, 1])\n","After flatten x torch.Size([32, 64])\n","After linear x torch.Size([32, 32])\n","After dropout x torch.Size([32, 32])\n","output xtorch.Size([32, 2])\n","initial x torch.Size([32, 3, 9, 9])\n","conv1 x torch.Size([32, 16, 4, 4])\n","conv2 x torch.Size([32, 32, 2, 2])\n","conv3 x torch.Size([32, 64, 1, 1])\n","After flatten x torch.Size([32, 64])\n","After linear x torch.Size([32, 32])\n","After dropout x torch.Size([32, 32])\n","output xtorch.Size([32, 2])\n","initial x torch.Size([32, 3, 9, 9])\n","conv1 x torch.Size([32, 16, 4, 4])\n","conv2 x torch.Size([32, 32, 2, 2])\n","conv3 x torch.Size([32, 64, 1, 1])\n","After flatten x torch.Size([32, 64])\n","After linear x torch.Size([32, 32])\n","After dropout x torch.Size([32, 32])\n","output xtorch.Size([32, 2])\n","initial x torch.Size([32, 3, 9, 9])\n","conv1 x torch.Size([32, 16, 4, 4])\n","conv2 x torch.Size([32, 32, 2, 2])\n","conv3 x torch.Size([32, 64, 1, 1])\n","After flatten x torch.Size([32, 64])\n","After linear x torch.Size([32, 32])\n","After dropout x torch.Size([32, 32])\n","output xtorch.Size([32, 2])\n","initial x torch.Size([32, 3, 9, 9])\n","conv1 x torch.Size([32, 16, 4, 4])\n","conv2 x torch.Size([32, 32, 2, 2])\n","conv3 x torch.Size([32, 64, 1, 1])\n","After flatten x torch.Size([32, 64])\n","After linear x torch.Size([32, 32])\n","After dropout x torch.Size([32, 32])\n","output xtorch.Size([32, 2])\n","initial x torch.Size([32, 3, 9, 9])\n","conv1 x torch.Size([32, 16, 4, 4])\n","conv2 x torch.Size([32, 32, 2, 2])\n","conv3 x torch.Size([32, 64, 1, 1])\n","After flatten x torch.Size([32, 64])\n","After linear x torch.Size([32, 32])\n","After dropout x torch.Size([32, 32])\n","output xtorch.Size([32, 2])\n","initial x torch.Size([32, 3, 9, 9])\n","conv1 x torch.Size([32, 16, 4, 4])\n","conv2 x torch.Size([32, 32, 2, 2])\n","conv3 x torch.Size([32, 64, 1, 1])\n","After flatten x torch.Size([32, 64])\n","After linear x torch.Size([32, 32])\n","After dropout x torch.Size([32, 32])\n","output xtorch.Size([32, 2])\n","initial x torch.Size([32, 3, 9, 9])\n","conv1 x torch.Size([32, 16, 4, 4])\n","conv2 x torch.Size([32, 32, 2, 2])\n","conv3 x torch.Size([32, 64, 1, 1])\n","After flatten x torch.Size([32, 64])\n","After linear x torch.Size([32, 32])\n","After dropout x torch.Size([32, 32])\n","output xtorch.Size([32, 2])\n","initial x torch.Size([32, 3, 9, 9])\n","conv1 x torch.Size([32, 16, 4, 4])\n","conv2 x torch.Size([32, 32, 2, 2])\n","conv3 x torch.Size([32, 64, 1, 1])\n","After flatten x torch.Size([32, 64])\n","After linear x torch.Size([32, 32])\n","After dropout x torch.Size([32, 32])\n","output xtorch.Size([32, 2])\n","initial x torch.Size([32, 3, 9, 9])\n","conv1 x torch.Size([32, 16, 4, 4])\n","conv2 x torch.Size([32, 32, 2, 2])\n","conv3 x torch.Size([32, 64, 1, 1])\n","After flatten x torch.Size([32, 64])\n","After linear x torch.Size([32, 32])\n","After dropout x torch.Size([32, 32])\n","output xtorch.Size([32, 2])\n","initial x torch.Size([32, 3, 9, 9])\n","conv1 x torch.Size([32, 16, 4, 4])\n","conv2 x torch.Size([32, 32, 2, 2])\n","conv3 x torch.Size([32, 64, 1, 1])\n","After flatten x torch.Size([32, 64])\n","After linear x torch.Size([32, 32])\n","After dropout x torch.Size([32, 32])\n","output xtorch.Size([32, 2])\n","initial x torch.Size([32, 3, 9, 9])\n","conv1 x torch.Size([32, 16, 4, 4])\n","conv2 x torch.Size([32, 32, 2, 2])\n","conv3 x torch.Size([32, 64, 1, 1])\n","After flatten x torch.Size([32, 64])\n","After linear x torch.Size([32, 32])\n","After dropout x torch.Size([32, 32])\n","output xtorch.Size([32, 2])\n","initial x torch.Size([32, 3, 9, 9])\n","conv1 x torch.Size([32, 16, 4, 4])\n","conv2 x torch.Size([32, 32, 2, 2])\n","conv3 x torch.Size([32, 64, 1, 1])\n","After flatten x torch.Size([32, 64])\n","After linear x torch.Size([32, 32])\n","After dropout x torch.Size([32, 32])\n","output xtorch.Size([32, 2])\n","initial x torch.Size([32, 3, 9, 9])\n","conv1 x torch.Size([32, 16, 4, 4])\n","conv2 x torch.Size([32, 32, 2, 2])\n","conv3 x torch.Size([32, 64, 1, 1])\n","After flatten x torch.Size([32, 64])\n","After linear x torch.Size([32, 32])\n","After dropout x torch.Size([32, 32])\n","output xtorch.Size([32, 2])\n","initial x torch.Size([32, 3, 9, 9])\n","conv1 x torch.Size([32, 16, 4, 4])\n","conv2 x torch.Size([32, 32, 2, 2])\n","conv3 x torch.Size([32, 64, 1, 1])\n","After flatten x torch.Size([32, 64])\n","After linear x torch.Size([32, 32])\n","After dropout x torch.Size([32, 32])\n","output xtorch.Size([32, 2])\n","initial x torch.Size([32, 3, 9, 9])\n","conv1 x torch.Size([32, 16, 4, 4])\n","conv2 x torch.Size([32, 32, 2, 2])\n","conv3 x torch.Size([32, 64, 1, 1])\n","After flatten x torch.Size([32, 64])\n","After linear x torch.Size([32, 32])\n","After dropout x torch.Size([32, 32])\n","output xtorch.Size([32, 2])\n","initial x torch.Size([32, 3, 9, 9])\n","conv1 x torch.Size([32, 16, 4, 4])\n","conv2 x torch.Size([32, 32, 2, 2])\n","conv3 x torch.Size([32, 64, 1, 1])\n","After flatten x torch.Size([32, 64])\n","After linear x torch.Size([32, 32])\n","After dropout x torch.Size([32, 32])\n","output xtorch.Size([32, 2])\n","initial x torch.Size([32, 3, 9, 9])\n","conv1 x torch.Size([32, 16, 4, 4])\n","conv2 x torch.Size([32, 32, 2, 2])\n","conv3 x torch.Size([32, 64, 1, 1])\n","After flatten x torch.Size([32, 64])\n","After linear x torch.Size([32, 32])\n","After dropout x torch.Size([32, 32])\n","output xtorch.Size([32, 2])\n","initial x torch.Size([32, 3, 9, 9])\n","conv1 x torch.Size([32, 16, 4, 4])\n","conv2 x torch.Size([32, 32, 2, 2])\n","conv3 x torch.Size([32, 64, 1, 1])\n","After flatten x torch.Size([32, 64])\n","After linear x torch.Size([32, 32])\n","After dropout x torch.Size([32, 32])\n","output xtorch.Size([32, 2])\n","initial x torch.Size([32, 3, 9, 9])\n","conv1 x torch.Size([32, 16, 4, 4])\n","conv2 x torch.Size([32, 32, 2, 2])\n","conv3 x torch.Size([32, 64, 1, 1])\n","After flatten x torch.Size([32, 64])\n","After linear x torch.Size([32, 32])\n","After dropout x torch.Size([32, 32])\n","output xtorch.Size([32, 2])\n","initial x torch.Size([32, 3, 9, 9])\n","conv1 x torch.Size([32, 16, 4, 4])\n","conv2 x torch.Size([32, 32, 2, 2])\n","conv3 x torch.Size([32, 64, 1, 1])\n","After flatten x torch.Size([32, 64])\n","After linear x torch.Size([32, 32])\n","After dropout x torch.Size([32, 32])\n","output xtorch.Size([32, 2])\n","initial x torch.Size([32, 3, 9, 9])\n","conv1 x torch.Size([32, 16, 4, 4])\n","conv2 x torch.Size([32, 32, 2, 2])\n","conv3 x torch.Size([32, 64, 1, 1])\n","After flatten x torch.Size([32, 64])\n","After linear x torch.Size([32, 32])\n","After dropout x torch.Size([32, 32])\n","output xtorch.Size([32, 2])\n","initial x torch.Size([32, 3, 9, 9])\n","conv1 x torch.Size([32, 16, 4, 4])\n","conv2 x torch.Size([32, 32, 2, 2])\n","conv3 x torch.Size([32, 64, 1, 1])\n","After flatten x torch.Size([32, 64])\n","After linear x torch.Size([32, 32])\n","After dropout x torch.Size([32, 32])\n","output xtorch.Size([32, 2])\n","initial x torch.Size([32, 3, 9, 9])\n","conv1 x torch.Size([32, 16, 4, 4])\n","conv2 x torch.Size([32, 32, 2, 2])\n","conv3 x torch.Size([32, 64, 1, 1])\n","After flatten x torch.Size([32, 64])\n","After linear x torch.Size([32, 32])\n","After dropout x torch.Size([32, 32])\n","output xtorch.Size([32, 2])\n","initial x torch.Size([32, 3, 9, 9])\n","conv1 x torch.Size([32, 16, 4, 4])\n","conv2 x torch.Size([32, 32, 2, 2])\n","conv3 x torch.Size([32, 64, 1, 1])\n","After flatten x torch.Size([32, 64])\n","After linear x torch.Size([32, 32])\n","After dropout x torch.Size([32, 32])\n","output xtorch.Size([32, 2])\n","initial x torch.Size([32, 3, 9, 9])\n","conv1 x torch.Size([32, 16, 4, 4])\n","conv2 x torch.Size([32, 32, 2, 2])\n","conv3 x torch.Size([32, 64, 1, 1])\n","After flatten x torch.Size([32, 64])\n","After linear x torch.Size([32, 32])\n","After dropout x torch.Size([32, 32])\n","output xtorch.Size([32, 2])\n","initial x torch.Size([32, 3, 9, 9])\n","conv1 x torch.Size([32, 16, 4, 4])\n","conv2 x torch.Size([32, 32, 2, 2])\n","conv3 x torch.Size([32, 64, 1, 1])\n","After flatten x torch.Size([32, 64])\n","After linear x torch.Size([32, 32])\n","After dropout x torch.Size([32, 32])\n","output xtorch.Size([32, 2])\n","initial x torch.Size([32, 3, 9, 9])\n","conv1 x torch.Size([32, 16, 4, 4])\n","conv2 x torch.Size([32, 32, 2, 2])\n","conv3 x torch.Size([32, 64, 1, 1])\n","After flatten x torch.Size([32, 64])\n","After linear x torch.Size([32, 32])\n","After dropout x torch.Size([32, 32])\n","output xtorch.Size([32, 2])\n","initial x torch.Size([32, 3, 9, 9])\n","conv1 x torch.Size([32, 16, 4, 4])\n","conv2 x torch.Size([32, 32, 2, 2])\n","conv3 x torch.Size([32, 64, 1, 1])\n","After flatten x torch.Size([32, 64])\n","After linear x torch.Size([32, 32])\n","After dropout x torch.Size([32, 32])\n","output xtorch.Size([32, 2])\n","initial x torch.Size([32, 3, 9, 9])\n","conv1 x torch.Size([32, 16, 4, 4])\n","conv2 x torch.Size([32, 32, 2, 2])\n","conv3 x torch.Size([32, 64, 1, 1])\n","After flatten x torch.Size([32, 64])\n","After linear x torch.Size([32, 32])\n","After dropout x torch.Size([32, 32])\n","output xtorch.Size([32, 2])\n","initial x torch.Size([32, 3, 9, 9])\n","conv1 x torch.Size([32, 16, 4, 4])\n","conv2 x torch.Size([32, 32, 2, 2])\n","conv3 x torch.Size([32, 64, 1, 1])\n","After flatten x torch.Size([32, 64])\n","After linear x torch.Size([32, 32])\n","After dropout x torch.Size([32, 32])\n","output xtorch.Size([32, 2])\n","initial x torch.Size([32, 3, 9, 9])\n","conv1 x torch.Size([32, 16, 4, 4])\n","conv2 x torch.Size([32, 32, 2, 2])\n","conv3 x torch.Size([32, 64, 1, 1])\n","After flatten x torch.Size([32, 64])\n","After linear x torch.Size([32, 32])\n","After dropout x torch.Size([32, 32])\n","output xtorch.Size([32, 2])\n","initial x torch.Size([32, 3, 9, 9])\n","conv1 x torch.Size([32, 16, 4, 4])\n","conv2 x torch.Size([32, 32, 2, 2])\n","conv3 x torch.Size([32, 64, 1, 1])\n","After flatten x torch.Size([32, 64])\n","After linear x torch.Size([32, 32])\n","After dropout x torch.Size([32, 32])\n","output xtorch.Size([32, 2])\n","initial x torch.Size([32, 3, 9, 9])\n","conv1 x torch.Size([32, 16, 4, 4])\n","conv2 x torch.Size([32, 32, 2, 2])\n","conv3 x torch.Size([32, 64, 1, 1])\n","After flatten x torch.Size([32, 64])\n","After linear x torch.Size([32, 32])\n","After dropout x torch.Size([32, 32])\n","output xtorch.Size([32, 2])\n","initial x torch.Size([32, 3, 9, 9])\n","conv1 x torch.Size([32, 16, 4, 4])\n","conv2 x torch.Size([32, 32, 2, 2])\n","conv3 x torch.Size([32, 64, 1, 1])\n","After flatten x torch.Size([32, 64])\n","After linear x torch.Size([32, 32])\n","After dropout x torch.Size([32, 32])\n","output xtorch.Size([32, 2])\n","initial x torch.Size([32, 3, 9, 9])\n","conv1 x torch.Size([32, 16, 4, 4])\n","conv2 x torch.Size([32, 32, 2, 2])\n","conv3 x torch.Size([32, 64, 1, 1])\n","After flatten x torch.Size([32, 64])\n","After linear x torch.Size([32, 32])\n","After dropout x torch.Size([32, 32])\n","output xtorch.Size([32, 2])\n","initial x torch.Size([32, 3, 9, 9])\n","conv1 x torch.Size([32, 16, 4, 4])\n","conv2 x torch.Size([32, 32, 2, 2])\n","conv3 x torch.Size([32, 64, 1, 1])\n","After flatten x torch.Size([32, 64])\n","After linear x torch.Size([32, 32])\n","After dropout x torch.Size([32, 32])\n","output xtorch.Size([32, 2])\n","initial x torch.Size([32, 3, 9, 9])\n","conv1 x torch.Size([32, 16, 4, 4])\n","conv2 x torch.Size([32, 32, 2, 2])\n","conv3 x torch.Size([32, 64, 1, 1])\n","After flatten x torch.Size([32, 64])\n","After linear x torch.Size([32, 32])\n","After dropout x torch.Size([32, 32])\n","output xtorch.Size([32, 2])\n","initial x torch.Size([32, 3, 9, 9])\n","conv1 x torch.Size([32, 16, 4, 4])\n","conv2 x torch.Size([32, 32, 2, 2])\n","conv3 x torch.Size([32, 64, 1, 1])\n","After flatten x torch.Size([32, 64])\n","After linear x torch.Size([32, 32])\n","After dropout x torch.Size([32, 32])\n","output xtorch.Size([32, 2])\n","initial x torch.Size([32, 3, 9, 9])\n","conv1 x torch.Size([32, 16, 4, 4])\n","conv2 x torch.Size([32, 32, 2, 2])\n","conv3 x torch.Size([32, 64, 1, 1])\n","After flatten x torch.Size([32, 64])\n","After linear x torch.Size([32, 32])\n","After dropout x torch.Size([32, 32])\n","output xtorch.Size([32, 2])\n","initial x torch.Size([32, 3, 9, 9])\n","conv1 x torch.Size([32, 16, 4, 4])\n","conv2 x torch.Size([32, 32, 2, 2])\n","conv3 x torch.Size([32, 64, 1, 1])\n","After flatten x torch.Size([32, 64])\n","After linear x torch.Size([32, 32])\n","After dropout x torch.Size([32, 32])\n","output xtorch.Size([32, 2])\n","initial x torch.Size([32, 3, 9, 9])\n","conv1 x torch.Size([32, 16, 4, 4])\n","conv2 x torch.Size([32, 32, 2, 2])\n","conv3 x torch.Size([32, 64, 1, 1])\n","After flatten x torch.Size([32, 64])\n","After linear x torch.Size([32, 32])\n","After dropout x torch.Size([32, 32])\n","output xtorch.Size([32, 2])\n","initial x torch.Size([32, 3, 9, 9])\n","conv1 x torch.Size([32, 16, 4, 4])\n","conv2 x torch.Size([32, 32, 2, 2])\n","conv3 x torch.Size([32, 64, 1, 1])\n","After flatten x torch.Size([32, 64])\n","After linear x torch.Size([32, 32])\n","After dropout x torch.Size([32, 32])\n","output xtorch.Size([32, 2])\n","initial x torch.Size([32, 3, 9, 9])\n","conv1 x torch.Size([32, 16, 4, 4])\n","conv2 x torch.Size([32, 32, 2, 2])\n","conv3 x torch.Size([32, 64, 1, 1])\n","After flatten x torch.Size([32, 64])\n","After linear x torch.Size([32, 32])\n","After dropout x torch.Size([32, 32])\n","output xtorch.Size([32, 2])\n","initial x torch.Size([32, 3, 9, 9])\n","conv1 x torch.Size([32, 16, 4, 4])\n","conv2 x torch.Size([32, 32, 2, 2])\n","conv3 x torch.Size([32, 64, 1, 1])\n","After flatten x torch.Size([32, 64])\n","After linear x torch.Size([32, 32])\n","After dropout x torch.Size([32, 32])\n","output xtorch.Size([32, 2])\n","initial x torch.Size([32, 3, 9, 9])\n","conv1 x torch.Size([32, 16, 4, 4])\n","conv2 x torch.Size([32, 32, 2, 2])\n","conv3 x torch.Size([32, 64, 1, 1])\n","After flatten x torch.Size([32, 64])\n","After linear x torch.Size([32, 32])\n","After dropout x torch.Size([32, 32])\n","output xtorch.Size([32, 2])\n","initial x torch.Size([32, 3, 9, 9])\n","conv1 x torch.Size([32, 16, 4, 4])\n","conv2 x torch.Size([32, 32, 2, 2])\n","conv3 x torch.Size([32, 64, 1, 1])\n","After flatten x torch.Size([32, 64])\n","After linear x torch.Size([32, 32])\n","After dropout x torch.Size([32, 32])\n","output xtorch.Size([32, 2])\n","initial x torch.Size([32, 3, 9, 9])\n","conv1 x torch.Size([32, 16, 4, 4])\n","conv2 x torch.Size([32, 32, 2, 2])\n","conv3 x torch.Size([32, 64, 1, 1])\n","After flatten x torch.Size([32, 64])\n","After linear x torch.Size([32, 32])\n","After dropout x torch.Size([32, 32])\n","output xtorch.Size([32, 2])\n","initial x torch.Size([32, 3, 9, 9])\n","conv1 x torch.Size([32, 16, 4, 4])\n","conv2 x torch.Size([32, 32, 2, 2])\n","conv3 x torch.Size([32, 64, 1, 1])\n","After flatten x torch.Size([32, 64])\n","After linear x torch.Size([32, 32])\n","After dropout x torch.Size([32, 32])\n","output xtorch.Size([32, 2])\n","initial x torch.Size([32, 3, 9, 9])\n","conv1 x torch.Size([32, 16, 4, 4])\n","conv2 x torch.Size([32, 32, 2, 2])\n","conv3 x torch.Size([32, 64, 1, 1])\n","After flatten x torch.Size([32, 64])\n","After linear x torch.Size([32, 32])\n","After dropout x torch.Size([32, 32])\n","output xtorch.Size([32, 2])\n","initial x torch.Size([32, 3, 9, 9])\n","conv1 x torch.Size([32, 16, 4, 4])\n","conv2 x torch.Size([32, 32, 2, 2])\n","conv3 x torch.Size([32, 64, 1, 1])\n","After flatten x torch.Size([32, 64])\n","After linear x torch.Size([32, 32])\n","After dropout x torch.Size([32, 32])\n","output xtorch.Size([32, 2])\n","initial x torch.Size([32, 3, 9, 9])\n","conv1 x torch.Size([32, 16, 4, 4])\n","conv2 x torch.Size([32, 32, 2, 2])\n","conv3 x torch.Size([32, 64, 1, 1])\n","After flatten x torch.Size([32, 64])\n","After linear x torch.Size([32, 32])\n","After dropout x torch.Size([32, 32])\n","output xtorch.Size([32, 2])\n","initial x torch.Size([32, 3, 9, 9])\n","conv1 x torch.Size([32, 16, 4, 4])\n","conv2 x torch.Size([32, 32, 2, 2])\n","conv3 x torch.Size([32, 64, 1, 1])\n","After flatten x torch.Size([32, 64])\n","After linear x torch.Size([32, 32])\n","After dropout x torch.Size([32, 32])\n","output xtorch.Size([32, 2])\n","initial x torch.Size([32, 3, 9, 9])\n","conv1 x torch.Size([32, 16, 4, 4])\n","conv2 x torch.Size([32, 32, 2, 2])\n","conv3 x torch.Size([32, 64, 1, 1])\n","After flatten x torch.Size([32, 64])\n","After linear x torch.Size([32, 32])\n","After dropout x torch.Size([32, 32])\n","output xtorch.Size([32, 2])\n","initial x torch.Size([32, 3, 9, 9])\n","conv1 x torch.Size([32, 16, 4, 4])\n","conv2 x torch.Size([32, 32, 2, 2])\n","conv3 x torch.Size([32, 64, 1, 1])\n","After flatten x torch.Size([32, 64])\n","After linear x torch.Size([32, 32])\n","After dropout x torch.Size([32, 32])\n","output xtorch.Size([32, 2])\n","initial x torch.Size([32, 3, 9, 9])\n","conv1 x torch.Size([32, 16, 4, 4])\n","conv2 x torch.Size([32, 32, 2, 2])\n","conv3 x torch.Size([32, 64, 1, 1])\n","After flatten x torch.Size([32, 64])\n","After linear x torch.Size([32, 32])\n","After dropout x torch.Size([32, 32])\n","output xtorch.Size([32, 2])\n","initial x torch.Size([32, 3, 9, 9])\n","conv1 x torch.Size([32, 16, 4, 4])\n","conv2 x torch.Size([32, 32, 2, 2])\n","conv3 x torch.Size([32, 64, 1, 1])\n","After flatten x torch.Size([32, 64])\n","After linear x torch.Size([32, 32])\n","After dropout x torch.Size([32, 32])\n","output xtorch.Size([32, 2])\n","initial x torch.Size([32, 3, 9, 9])\n","conv1 x torch.Size([32, 16, 4, 4])\n","conv2 x torch.Size([32, 32, 2, 2])\n","conv3 x torch.Size([32, 64, 1, 1])\n","After flatten x torch.Size([32, 64])\n","After linear x torch.Size([32, 32])\n","After dropout x torch.Size([32, 32])\n","output xtorch.Size([32, 2])\n","initial x torch.Size([32, 3, 9, 9])\n","conv1 x torch.Size([32, 16, 4, 4])\n","conv2 x torch.Size([32, 32, 2, 2])\n","conv3 x torch.Size([32, 64, 1, 1])\n","After flatten x torch.Size([32, 64])\n","After linear x torch.Size([32, 32])\n","After dropout x torch.Size([32, 32])\n","output xtorch.Size([32, 2])\n","initial x torch.Size([32, 3, 9, 9])\n","conv1 x torch.Size([32, 16, 4, 4])\n","conv2 x torch.Size([32, 32, 2, 2])\n","conv3 x torch.Size([32, 64, 1, 1])\n","After flatten x torch.Size([32, 64])\n","After linear x torch.Size([32, 32])\n","After dropout x torch.Size([32, 32])\n","output xtorch.Size([32, 2])\n","initial x torch.Size([32, 3, 9, 9])\n","conv1 x torch.Size([32, 16, 4, 4])\n","conv2 x torch.Size([32, 32, 2, 2])\n","conv3 x torch.Size([32, 64, 1, 1])\n","After flatten x torch.Size([32, 64])\n","After linear x torch.Size([32, 32])\n","After dropout x torch.Size([32, 32])\n","output xtorch.Size([32, 2])\n","initial x torch.Size([32, 3, 9, 9])\n","conv1 x torch.Size([32, 16, 4, 4])\n","conv2 x torch.Size([32, 32, 2, 2])\n","conv3 x torch.Size([32, 64, 1, 1])\n","After flatten x torch.Size([32, 64])\n","After linear x torch.Size([32, 32])\n","After dropout x torch.Size([32, 32])\n","output xtorch.Size([32, 2])\n","initial x torch.Size([32, 3, 9, 9])\n","conv1 x torch.Size([32, 16, 4, 4])\n","conv2 x torch.Size([32, 32, 2, 2])\n","conv3 x torch.Size([32, 64, 1, 1])\n","After flatten x torch.Size([32, 64])\n","After linear x torch.Size([32, 32])\n","After dropout x torch.Size([32, 32])\n","output xtorch.Size([32, 2])\n","initial x torch.Size([32, 3, 9, 9])\n","conv1 x torch.Size([32, 16, 4, 4])\n","conv2 x torch.Size([32, 32, 2, 2])\n","conv3 x torch.Size([32, 64, 1, 1])\n","After flatten x torch.Size([32, 64])\n","After linear x torch.Size([32, 32])\n","After dropout x torch.Size([32, 32])\n","output xtorch.Size([32, 2])\n","initial x torch.Size([32, 3, 9, 9])\n","conv1 x torch.Size([32, 16, 4, 4])\n","conv2 x torch.Size([32, 32, 2, 2])\n","conv3 x torch.Size([32, 64, 1, 1])\n","After flatten x torch.Size([32, 64])\n","After linear x torch.Size([32, 32])\n","After dropout x torch.Size([32, 32])\n","output xtorch.Size([32, 2])\n","initial x torch.Size([32, 3, 9, 9])\n","conv1 x torch.Size([32, 16, 4, 4])\n","conv2 x torch.Size([32, 32, 2, 2])\n","conv3 x torch.Size([32, 64, 1, 1])\n","After flatten x torch.Size([32, 64])\n","After linear x torch.Size([32, 32])\n","After dropout x torch.Size([32, 32])\n","output xtorch.Size([32, 2])\n","initial x torch.Size([32, 3, 9, 9])\n","conv1 x torch.Size([32, 16, 4, 4])\n","conv2 x torch.Size([32, 32, 2, 2])\n","conv3 x torch.Size([32, 64, 1, 1])\n","After flatten x torch.Size([32, 64])\n","After linear x torch.Size([32, 32])\n","After dropout x torch.Size([32, 32])\n","output xtorch.Size([32, 2])\n","initial x torch.Size([32, 3, 9, 9])\n","conv1 x torch.Size([32, 16, 4, 4])\n","conv2 x torch.Size([32, 32, 2, 2])\n","conv3 x torch.Size([32, 64, 1, 1])\n","After flatten x torch.Size([32, 64])\n","After linear x torch.Size([32, 32])\n","After dropout x torch.Size([32, 32])\n","output xtorch.Size([32, 2])\n","initial x torch.Size([32, 3, 9, 9])\n","conv1 x torch.Size([32, 16, 4, 4])\n","conv2 x torch.Size([32, 32, 2, 2])\n","conv3 x torch.Size([32, 64, 1, 1])\n","After flatten x torch.Size([32, 64])\n","After linear x torch.Size([32, 32])\n","After dropout x torch.Size([32, 32])\n","output xtorch.Size([32, 2])\n","initial x torch.Size([32, 3, 9, 9])\n","conv1 x torch.Size([32, 16, 4, 4])\n","conv2 x torch.Size([32, 32, 2, 2])\n","conv3 x torch.Size([32, 64, 1, 1])\n","After flatten x torch.Size([32, 64])\n","After linear x torch.Size([32, 32])\n","After dropout x torch.Size([32, 32])\n","output xtorch.Size([32, 2])\n","initial x torch.Size([32, 3, 9, 9])\n","conv1 x torch.Size([32, 16, 4, 4])\n","conv2 x torch.Size([32, 32, 2, 2])\n","conv3 x torch.Size([32, 64, 1, 1])\n","After flatten x torch.Size([32, 64])\n","After linear x torch.Size([32, 32])\n","After dropout x torch.Size([32, 32])\n","output xtorch.Size([32, 2])\n","initial x torch.Size([32, 3, 9, 9])\n","conv1 x torch.Size([32, 16, 4, 4])\n","conv2 x torch.Size([32, 32, 2, 2])\n","conv3 x torch.Size([32, 64, 1, 1])\n","After flatten x torch.Size([32, 64])\n","After linear x torch.Size([32, 32])\n","After dropout x torch.Size([32, 32])\n","output xtorch.Size([32, 2])\n","initial x torch.Size([32, 3, 9, 9])\n","conv1 x torch.Size([32, 16, 4, 4])\n","conv2 x torch.Size([32, 32, 2, 2])\n","conv3 x torch.Size([32, 64, 1, 1])\n","After flatten x torch.Size([32, 64])\n","After linear x torch.Size([32, 32])\n","After dropout x torch.Size([32, 32])\n","output xtorch.Size([32, 2])\n","initial x torch.Size([32, 3, 9, 9])\n","conv1 x torch.Size([32, 16, 4, 4])\n","conv2 x torch.Size([32, 32, 2, 2])\n","conv3 x torch.Size([32, 64, 1, 1])\n","After flatten x torch.Size([32, 64])\n","After linear x torch.Size([32, 32])\n","After dropout x torch.Size([32, 32])\n","output xtorch.Size([32, 2])\n","initial x torch.Size([32, 3, 9, 9])\n","conv1 x torch.Size([32, 16, 4, 4])\n","conv2 x torch.Size([32, 32, 2, 2])\n","conv3 x torch.Size([32, 64, 1, 1])\n","After flatten x torch.Size([32, 64])\n","After linear x torch.Size([32, 32])\n","After dropout x torch.Size([32, 32])\n","output xtorch.Size([32, 2])\n","initial x torch.Size([32, 3, 9, 9])\n","conv1 x torch.Size([32, 16, 4, 4])\n","conv2 x torch.Size([32, 32, 2, 2])\n","conv3 x torch.Size([32, 64, 1, 1])\n","After flatten x torch.Size([32, 64])\n","After linear x torch.Size([32, 32])\n","After dropout x torch.Size([32, 32])\n","output xtorch.Size([32, 2])\n","initial x torch.Size([32, 3, 9, 9])\n","conv1 x torch.Size([32, 16, 4, 4])\n","conv2 x torch.Size([32, 32, 2, 2])\n","conv3 x torch.Size([32, 64, 1, 1])\n","After flatten x torch.Size([32, 64])\n","After linear x torch.Size([32, 32])\n","After dropout x torch.Size([32, 32])\n","output xtorch.Size([32, 2])\n","initial x torch.Size([32, 3, 9, 9])\n","conv1 x torch.Size([32, 16, 4, 4])\n","conv2 x torch.Size([32, 32, 2, 2])\n","conv3 x torch.Size([32, 64, 1, 1])\n","After flatten x torch.Size([32, 64])\n","After linear x torch.Size([32, 32])\n","After dropout x torch.Size([32, 32])\n","output xtorch.Size([32, 2])\n","initial x torch.Size([32, 3, 9, 9])\n","conv1 x torch.Size([32, 16, 4, 4])\n","conv2 x torch.Size([32, 32, 2, 2])\n","conv3 x torch.Size([32, 64, 1, 1])\n","After flatten x torch.Size([32, 64])\n","After linear x torch.Size([32, 32])\n","After dropout x torch.Size([32, 32])\n","output xtorch.Size([32, 2])\n","initial x torch.Size([32, 3, 9, 9])\n","conv1 x torch.Size([32, 16, 4, 4])\n","conv2 x torch.Size([32, 32, 2, 2])\n","conv3 x torch.Size([32, 64, 1, 1])\n","After flatten x torch.Size([32, 64])\n","After linear x torch.Size([32, 32])\n","After dropout x torch.Size([32, 32])\n","output xtorch.Size([32, 2])\n","initial x torch.Size([32, 3, 9, 9])\n","conv1 x torch.Size([32, 16, 4, 4])\n","conv2 x torch.Size([32, 32, 2, 2])\n","conv3 x torch.Size([32, 64, 1, 1])\n","After flatten x torch.Size([32, 64])\n","After linear x torch.Size([32, 32])\n","After dropout x torch.Size([32, 32])\n","output xtorch.Size([32, 2])\n","initial x torch.Size([32, 3, 9, 9])\n","conv1 x torch.Size([32, 16, 4, 4])\n","conv2 x torch.Size([32, 32, 2, 2])\n","conv3 x torch.Size([32, 64, 1, 1])\n","After flatten x torch.Size([32, 64])\n","After linear x torch.Size([32, 32])\n","After dropout x torch.Size([32, 32])\n","output xtorch.Size([32, 2])\n","initial x torch.Size([32, 3, 9, 9])\n","conv1 x torch.Size([32, 16, 4, 4])\n","conv2 x torch.Size([32, 32, 2, 2])\n","conv3 x torch.Size([32, 64, 1, 1])\n","After flatten x torch.Size([32, 64])\n","After linear x torch.Size([32, 32])\n","After dropout x torch.Size([32, 32])\n","output xtorch.Size([32, 2])\n","initial x torch.Size([32, 3, 9, 9])\n","conv1 x torch.Size([32, 16, 4, 4])\n","conv2 x torch.Size([32, 32, 2, 2])\n","conv3 x torch.Size([32, 64, 1, 1])\n","After flatten x torch.Size([32, 64])\n","After linear x torch.Size([32, 32])\n","After dropout x torch.Size([32, 32])\n","output xtorch.Size([32, 2])\n","initial x torch.Size([32, 3, 9, 9])\n","conv1 x torch.Size([32, 16, 4, 4])\n","conv2 x torch.Size([32, 32, 2, 2])\n","conv3 x torch.Size([32, 64, 1, 1])\n","After flatten x torch.Size([32, 64])\n","After linear x torch.Size([32, 32])\n","After dropout x torch.Size([32, 32])\n","output xtorch.Size([32, 2])\n","initial x torch.Size([32, 3, 9, 9])\n","conv1 x torch.Size([32, 16, 4, 4])\n","conv2 x torch.Size([32, 32, 2, 2])\n","conv3 x torch.Size([32, 64, 1, 1])\n","After flatten x torch.Size([32, 64])\n","After linear x torch.Size([32, 32])\n","After dropout x torch.Size([32, 32])\n","output xtorch.Size([32, 2])\n","initial x torch.Size([32, 3, 9, 9])\n","conv1 x torch.Size([32, 16, 4, 4])\n","conv2 x torch.Size([32, 32, 2, 2])\n","conv3 x torch.Size([32, 64, 1, 1])\n","After flatten x torch.Size([32, 64])\n","After linear x torch.Size([32, 32])\n","After dropout x torch.Size([32, 32])\n","output xtorch.Size([32, 2])\n","initial x torch.Size([32, 3, 9, 9])\n","conv1 x torch.Size([32, 16, 4, 4])\n","conv2 x torch.Size([32, 32, 2, 2])\n","conv3 x torch.Size([32, 64, 1, 1])\n","After flatten x torch.Size([32, 64])\n","After linear x torch.Size([32, 32])\n","After dropout x torch.Size([32, 32])\n","output xtorch.Size([32, 2])\n","initial x torch.Size([32, 3, 9, 9])\n","conv1 x torch.Size([32, 16, 4, 4])\n","conv2 x torch.Size([32, 32, 2, 2])\n","conv3 x torch.Size([32, 64, 1, 1])\n","After flatten x torch.Size([32, 64])\n","After linear x torch.Size([32, 32])\n","After dropout x torch.Size([32, 32])\n","output xtorch.Size([32, 2])\n","initial x torch.Size([32, 3, 9, 9])\n","conv1 x torch.Size([32, 16, 4, 4])\n","conv2 x torch.Size([32, 32, 2, 2])\n","conv3 x torch.Size([32, 64, 1, 1])\n","After flatten x torch.Size([32, 64])\n","After linear x torch.Size([32, 32])\n","After dropout x torch.Size([32, 32])\n","output xtorch.Size([32, 2])\n","initial x torch.Size([32, 3, 9, 9])\n","conv1 x torch.Size([32, 16, 4, 4])\n","conv2 x torch.Size([32, 32, 2, 2])\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[1;32m/Users/odaehyeok/Desktop/연구/Palette/GPT_CNN_Aro.ipynb Cell 3\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/odaehyeok/Desktop/%EC%97%B0%EA%B5%AC/Palette/GPT_CNN_Aro.ipynb#W2sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/odaehyeok/Desktop/%EC%97%B0%EA%B5%AC/Palette/GPT_CNN_Aro.ipynb#W2sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m \u001b[39m# 순전파 + 역전파 + 최적화를 한 후\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/odaehyeok/Desktop/%EC%97%B0%EA%B5%AC/Palette/GPT_CNN_Aro.ipynb#W2sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m outputs \u001b[39m=\u001b[39m net(inputs)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/odaehyeok/Desktop/%EC%97%B0%EA%B5%AC/Palette/GPT_CNN_Aro.ipynb#W2sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m \u001b[39m# print(outputs.shape)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/odaehyeok/Desktop/%EC%97%B0%EA%B5%AC/Palette/GPT_CNN_Aro.ipynb#W2sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m \u001b[39m# print(labels)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/odaehyeok/Desktop/%EC%97%B0%EA%B5%AC/Palette/GPT_CNN_Aro.ipynb#W2sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m loss \u001b[39m=\u001b[39m criterion(outputs, labels)\n","File \u001b[0;32m~/anaconda3/envs/palette/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n","\u001b[1;32m/Users/odaehyeok/Desktop/연구/Palette/GPT_CNN_Aro.ipynb Cell 3\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/odaehyeok/Desktop/%EC%97%B0%EA%B5%AC/Palette/GPT_CNN_Aro.ipynb#W2sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m x\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/odaehyeok/Desktop/%EC%97%B0%EA%B5%AC/Palette/GPT_CNN_Aro.ipynb#W2sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mconv2 x \u001b[39m\u001b[39m{\u001b[39;00mx\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/odaehyeok/Desktop/%EC%97%B0%EA%B5%AC/Palette/GPT_CNN_Aro.ipynb#W2sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpool(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbatch_norm3(torch\u001b[39m.\u001b[39;49mrelu(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv3(x))))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/odaehyeok/Desktop/%EC%97%B0%EA%B5%AC/Palette/GPT_CNN_Aro.ipynb#W2sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m x\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/odaehyeok/Desktop/%EC%97%B0%EA%B5%AC/Palette/GPT_CNN_Aro.ipynb#W2sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mconv3 x \u001b[39m\u001b[39m{\u001b[39;00mx\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n","File \u001b[0;32m~/anaconda3/envs/palette/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n","File \u001b[0;32m~/anaconda3/envs/palette/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py:171\u001b[0m, in \u001b[0;36m_BatchNorm.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    164\u001b[0m     bn_training \u001b[39m=\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrunning_mean \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m) \u001b[39mand\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrunning_var \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    166\u001b[0m \u001b[39m\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    167\u001b[0m \u001b[39mBuffers are only updated if they are to be tracked and we are in training mode. Thus they only need to be\u001b[39;00m\n\u001b[1;32m    168\u001b[0m \u001b[39mpassed when the update should occur (i.e. in training mode when they are tracked), or when buffer stats are\u001b[39;00m\n\u001b[1;32m    169\u001b[0m \u001b[39mused for normalization (i.e. in eval mode when buffers are not None).\u001b[39;00m\n\u001b[1;32m    170\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 171\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mbatch_norm(\n\u001b[1;32m    172\u001b[0m     \u001b[39minput\u001b[39;49m,\n\u001b[1;32m    173\u001b[0m     \u001b[39m# If buffers are not to be tracked, ensure that they won't be updated\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrunning_mean\n\u001b[1;32m    175\u001b[0m     \u001b[39mif\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining \u001b[39mor\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrack_running_stats\n\u001b[1;32m    176\u001b[0m     \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    177\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrunning_var \u001b[39mif\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining \u001b[39mor\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrack_running_stats \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    178\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight,\n\u001b[1;32m    179\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias,\n\u001b[1;32m    180\u001b[0m     bn_training,\n\u001b[1;32m    181\u001b[0m     exponential_average_factor,\n\u001b[1;32m    182\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49meps,\n\u001b[1;32m    183\u001b[0m )\n","File \u001b[0;32m~/anaconda3/envs/palette/lib/python3.11/site-packages/torch/nn/functional.py:2450\u001b[0m, in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   2447\u001b[0m \u001b[39mif\u001b[39;00m training:\n\u001b[1;32m   2448\u001b[0m     _verify_batch_size(\u001b[39minput\u001b[39m\u001b[39m.\u001b[39msize())\n\u001b[0;32m-> 2450\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49mbatch_norm(\n\u001b[1;32m   2451\u001b[0m     \u001b[39minput\u001b[39;49m, weight, bias, running_mean, running_var, training, momentum, eps, torch\u001b[39m.\u001b[39;49mbackends\u001b[39m.\u001b[39;49mcudnn\u001b[39m.\u001b[39;49menabled\n\u001b[1;32m   2452\u001b[0m )\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["from tqdm import tqdm\n","from tqdm import notebook\n","#학습\n","start_flag = 1\n","for epoch in range(2):   # 데이터셋을 수차례 반복합니다.\n","\n","    running_loss = 0.0\n","    for i, data in enumerate(notebook.tqdm(train_loader), 0):\n","\n","        if start_flag == 1:\n","            print(\"start learning!!!\")\n","            start_flag = 0\n","\n","        # [inputs, labels]의 목록인 data로부터 입력을 받은 후;\n","        inputs, labels = data\n","\n","        #검증\n","        # print(f\"minibatch number : {i}, file's shape : {inputs.shape}\")\n","\n","        #move to GPU to calculate\n","        inputs = inputs.to(device)\n","        labels = labels.to(device)\n","\n","        # 변화도(Gradient) 매개변수를 0으로 만들고\n","        optimizer.zero_grad()\n","\n","        # 순전파 + 역전파 + 최적화를 한 후\n","        outputs = net(inputs)\n","        # print(outputs.shape)\n","        # print(labels)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","        # 통계를 출력합니다.\n","        running_loss += loss.item()\n","        if i % 600 == 599:    # print every 600 mini-batches\n","            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n","            running_loss = 0.0\n","            \n","\n","print('Finished Training')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"m55gfISW24vm"},"outputs":[],"source":["##Save Model\n","PATH = \"/content/drive/MyDrive/models/\"\n","torch.save(net.state_dict(), PATH)"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"MEFECQ1bMqGy"},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy of the network on the 10000 test images:  56.795635 %\n"]}],"source":["#Accuracy Check\n","correct = 0\n","total = 0\n","# 학습 중이 아니므로, 출력에 대한 변화도를 계산할 필요가 없습니다\n","with torch.no_grad():\n","    for data in test_loader:\n","        images, labels = data\n","        # 신경망에 이미지를 통과시켜 출력을 계산합니다\n","        outputs = net(images)\n","        # 가장 높은 값(energy)를 갖는 분류(class)를 정답으로 선택하겠습니다\n","        _, predicted = torch.max(outputs.data, 1)\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","\n","print(f'Accuracy of the network on the 10000 test images: {100 * correct / total : .2f} %')"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.4"},"orig_nbformat":4,"widgets":{"application/vnd.jupyter.widget-state+json":{"1a37b57b03c141afb23bd96c9c60f2c8":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4106fcd31a1b4ab8b7ea3a73d4feef59":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"44f30e031c6a4eb4ba80c4c47c11fcb2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"57db90486c05493696ccd5dd12e1fa76":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4106fcd31a1b4ab8b7ea3a73d4feef59","placeholder":"​","style":"IPY_MODEL_8d439083db004ee2ad1e390d5498967c","value":" 13%"}},"5ae44592655b441b8a25dae83e08f514":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6402a280118a477eb43772732850421e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6c1a9e6e948346e08db35c1cdaa98142":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_57db90486c05493696ccd5dd12e1fa76","IPY_MODEL_83f6d083d59f4370adbf5ed05163fe80","IPY_MODEL_f3fc3fa138614c63849cc9788bcdfb63"],"layout":"IPY_MODEL_5ae44592655b441b8a25dae83e08f514"}},"83f6d083d59f4370adbf5ed05163fe80":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_1a37b57b03c141afb23bd96c9c60f2c8","max":1394,"min":0,"orientation":"horizontal","style":"IPY_MODEL_44f30e031c6a4eb4ba80c4c47c11fcb2","value":184}},"8d439083db004ee2ad1e390d5498967c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cbbe9289e69b4786820ddb7f88d860ce":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f3fc3fa138614c63849cc9788bcdfb63":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6402a280118a477eb43772732850421e","placeholder":"​","style":"IPY_MODEL_cbbe9289e69b4786820ddb7f88d860ce","value":" 184/1394 [1:08:51&lt;7:32:00, 22.41s/it]"}}}}},"nbformat":4,"nbformat_minor":0}
